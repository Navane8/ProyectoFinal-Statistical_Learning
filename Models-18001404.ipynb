{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\50259\\AppData\\Local\\Temp\\ipykernel_15624\\3068579679.py:1: DtypeWarning: Columns (26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv('train.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 28 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   ID                        100000 non-null  object \n",
      " 1   Customer_ID               100000 non-null  object \n",
      " 2   Month                     100000 non-null  object \n",
      " 3   Name                      90015 non-null   object \n",
      " 4   Age                       100000 non-null  object \n",
      " 5   SSN                       100000 non-null  object \n",
      " 6   Occupation                100000 non-null  object \n",
      " 7   Annual_Income             100000 non-null  object \n",
      " 8   Monthly_Inhand_Salary     84998 non-null   float64\n",
      " 9   Num_Bank_Accounts         100000 non-null  int64  \n",
      " 10  Num_Credit_Card           100000 non-null  int64  \n",
      " 11  Interest_Rate             100000 non-null  int64  \n",
      " 12  Num_of_Loan               100000 non-null  object \n",
      " 13  Type_of_Loan              88592 non-null   object \n",
      " 14  Delay_from_due_date       100000 non-null  int64  \n",
      " 15  Num_of_Delayed_Payment    92998 non-null   object \n",
      " 16  Changed_Credit_Limit      100000 non-null  object \n",
      " 17  Num_Credit_Inquiries      98035 non-null   float64\n",
      " 18  Credit_Mix                100000 non-null  object \n",
      " 19  Outstanding_Debt          100000 non-null  object \n",
      " 20  Credit_Utilization_Ratio  100000 non-null  float64\n",
      " 21  Credit_History_Age        90970 non-null   object \n",
      " 22  Payment_of_Min_Amount     100000 non-null  object \n",
      " 23  Total_EMI_per_month       100000 non-null  float64\n",
      " 24  Amount_invested_monthly   95521 non-null   object \n",
      " 25  Payment_Behaviour         100000 non-null  object \n",
      " 26  Monthly_Balance           98800 non-null   object \n",
      " 27  Credit_Score              100000 non-null  object \n",
      "dtypes: float64(4), int64(4), object(20)\n",
      "memory usage: 21.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('train.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se determina columnas que tienen nulos menor al 5% para poder realizar imputacion de datos\n",
    "cols_rescatables=[col for col in df.columns if (df[col].isnull().mean()<=0.05)]\n",
    "# Se quitan duplicados\n",
    "df.drop_duplicates(inplace=True)\n",
    "# Se crea dataset \n",
    "df_temp=df[cols_rescatables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\50259\\AppData\\Local\\Temp\\ipykernel_15624\\3529412718.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['Annual_Income'] = df['Annual_Income'].str.replace('_', '')\n",
      "C:\\Users\\50259\\AppData\\Local\\Temp\\ipykernel_15624\\3529412718.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['Outstanding_Debt'] = df['Outstanding_Debt'].str.replace('_', '')\n",
      "C:\\Users\\50259\\AppData\\Local\\Temp\\ipykernel_15624\\3529412718.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['Age'] = df['Age'].str.replace('_', '')\n",
      "C:\\Users\\50259\\AppData\\Local\\Temp\\ipykernel_15624\\3529412718.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['Num_of_Loan'] = df['Num_of_Loan'].str.replace('_', '')\n",
      "C:\\Users\\50259\\AppData\\Local\\Temp\\ipykernel_15624\\3529412718.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['Changed_Credit_Limit'] = df['Changed_Credit_Limit'].str.replace('_', '0')\n",
      "C:\\Users\\50259\\AppData\\Local\\Temp\\ipykernel_15624\\3529412718.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['Amount_invested_monthly'] = df['Amount_invested_monthly'].str.replace('__10000__', '10000')\n",
      "C:\\Users\\50259\\AppData\\Local\\Temp\\ipykernel_15624\\3529412718.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['Monthly_Balance'] = df['Monthly_Balance'].str.replace('__-333333333333333333333333333__', '33333333333333333')\n",
      "C:\\Users\\50259\\AppData\\Local\\Temp\\ipykernel_15624\\3529412718.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['Annual_Income'] = df_temp['Annual_Income'].astype(float)\n",
      "C:\\Users\\50259\\AppData\\Local\\Temp\\ipykernel_15624\\3529412718.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['Changed_Credit_Limit'] = df_temp['Changed_Credit_Limit'].astype(float)\n",
      "C:\\Users\\50259\\AppData\\Local\\Temp\\ipykernel_15624\\3529412718.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['Outstanding_Debt'] = df_temp['Outstanding_Debt'].astype(float)\n",
      "C:\\Users\\50259\\AppData\\Local\\Temp\\ipykernel_15624\\3529412718.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['Amount_invested_monthly'] = df_temp['Amount_invested_monthly'].astype(float)\n",
      "C:\\Users\\50259\\AppData\\Local\\Temp\\ipykernel_15624\\3529412718.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['Monthly_Balance'] = df_temp['Monthly_Balance'].astype(float)\n",
      "C:\\Users\\50259\\AppData\\Local\\Temp\\ipykernel_15624\\3529412718.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['Age'] = df_temp['Age'].astype(int)\n",
      "C:\\Users\\50259\\AppData\\Local\\Temp\\ipykernel_15624\\3529412718.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['Num_of_Loan'] = df_temp['Num_of_Loan'].astype(int)\n"
     ]
    }
   ],
   "source": [
    "# CONVERSION DE CATEGORICAS A NUMEROS \n",
    "\n",
    "# SE DETERMINA CARACTERES EXTRAÑOS QUE HAN DE SER REEMPLAZADOS PARA LOGRAR LA CONVERSION A NUMERO\n",
    "\n",
    "# En este caso 'numero_' debe ser 'numero' por tanto se hace el cambio '_' = ''\n",
    "df_temp['Annual_Income'] = df['Annual_Income'].str.replace('_', '')\n",
    "df_temp['Outstanding_Debt'] = df['Outstanding_Debt'].str.replace('_', '')\n",
    "df_temp['Age'] = df['Age'].str.replace('_', '')\n",
    "df_temp['Num_of_Loan'] = df['Num_of_Loan'].str.replace('_', '')\n",
    "\n",
    "# En este caso '_' debe ser '0' porque significa sin cambio en limite de credito, por tanto se reemplaza '_' = '0'\n",
    "df_temp['Changed_Credit_Limit'] = df['Changed_Credit_Limit'].str.replace('_', '0')\n",
    "\n",
    "# En este caso solo hay un numero con problema: ' __10000__' por tanto se sustituye con 10000\n",
    "df_temp['Amount_invested_monthly'] = df['Amount_invested_monthly'].str.replace('__10000__', '10000')\n",
    "# En este caso solo hay un numero con problema: _-3333333_ por tanto se sustituye con -3333333\n",
    "df_temp['Monthly_Balance'] = df['Monthly_Balance'].str.replace('__-333333333333333333333333333__', '33333333333333333')\n",
    "\n",
    "\n",
    "# CONVERTIR A NUMERICO \n",
    "\n",
    "# TIPO FLOAT\n",
    "\n",
    "df_temp['Annual_Income'] = df_temp['Annual_Income'].astype(float)\n",
    "df_temp['Changed_Credit_Limit'] = df_temp['Changed_Credit_Limit'].astype(float)\n",
    "df_temp['Outstanding_Debt'] = df_temp['Outstanding_Debt'].astype(float)\n",
    "df_temp['Amount_invested_monthly'] = df_temp['Amount_invested_monthly'].astype(float)\n",
    "df_temp['Monthly_Balance'] = df_temp['Monthly_Balance'].astype(float)\n",
    "\n",
    "# TIPO INT\n",
    "\n",
    "df_temp['Age'] = df_temp['Age'].astype(int)\n",
    "df_temp['Num_of_Loan'] = df_temp['Num_of_Loan'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Annual_Income</th>\n",
       "      <th>Num_Bank_Accounts</th>\n",
       "      <th>Num_Credit_Card</th>\n",
       "      <th>Interest_Rate</th>\n",
       "      <th>Num_of_Loan</th>\n",
       "      <th>Delay_from_due_date</th>\n",
       "      <th>Changed_Credit_Limit</th>\n",
       "      <th>Num_Credit_Inquiries</th>\n",
       "      <th>Outstanding_Debt</th>\n",
       "      <th>Credit_Utilization_Ratio</th>\n",
       "      <th>Total_EMI_per_month</th>\n",
       "      <th>Amount_invested_monthly</th>\n",
       "      <th>Monthly_Balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>1.000000e+05</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.00000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>98035.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>95521.000000</td>\n",
       "      <td>9.713200e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>110.649700</td>\n",
       "      <td>1.764157e+05</td>\n",
       "      <td>17.091280</td>\n",
       "      <td>22.47443</td>\n",
       "      <td>72.466040</td>\n",
       "      <td>3.009960</td>\n",
       "      <td>21.068780</td>\n",
       "      <td>10.171791</td>\n",
       "      <td>27.754251</td>\n",
       "      <td>1426.220376</td>\n",
       "      <td>32.285173</td>\n",
       "      <td>1403.118217</td>\n",
       "      <td>637.412998</td>\n",
       "      <td>3.088580e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>686.244717</td>\n",
       "      <td>1.429618e+06</td>\n",
       "      <td>117.404834</td>\n",
       "      <td>129.05741</td>\n",
       "      <td>466.422621</td>\n",
       "      <td>62.647879</td>\n",
       "      <td>14.860104</td>\n",
       "      <td>6.880628</td>\n",
       "      <td>193.177339</td>\n",
       "      <td>1155.129026</td>\n",
       "      <td>5.116875</td>\n",
       "      <td>8306.041270</td>\n",
       "      <td>2043.319327</td>\n",
       "      <td>3.208492e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-500.000000</td>\n",
       "      <td>7.005930e+03</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-6.490000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.759665e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.945750e+04</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.970000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>566.072500</td>\n",
       "      <td>28.052567</td>\n",
       "      <td>30.306660</td>\n",
       "      <td>74.534002</td>\n",
       "      <td>2.700037e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>3.757861e+04</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>9.250000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1166.155000</td>\n",
       "      <td>32.305784</td>\n",
       "      <td>69.249473</td>\n",
       "      <td>135.925682</td>\n",
       "      <td>3.364770e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>7.279092e+04</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>14.660000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1945.962500</td>\n",
       "      <td>36.496663</td>\n",
       "      <td>161.224249</td>\n",
       "      <td>265.731733</td>\n",
       "      <td>4.696852e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8698.000000</td>\n",
       "      <td>2.419806e+07</td>\n",
       "      <td>1798.000000</td>\n",
       "      <td>1499.00000</td>\n",
       "      <td>5797.000000</td>\n",
       "      <td>1496.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>36.970000</td>\n",
       "      <td>2597.000000</td>\n",
       "      <td>4998.070000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>82331.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>3.333333e+16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Age  Annual_Income  Num_Bank_Accounts  Num_Credit_Card  \\\n",
       "count  100000.000000   1.000000e+05      100000.000000     100000.00000   \n",
       "mean      110.649700   1.764157e+05          17.091280         22.47443   \n",
       "std       686.244717   1.429618e+06         117.404834        129.05741   \n",
       "min      -500.000000   7.005930e+03          -1.000000          0.00000   \n",
       "25%        24.000000   1.945750e+04           3.000000          4.00000   \n",
       "50%        33.000000   3.757861e+04           6.000000          5.00000   \n",
       "75%        42.000000   7.279092e+04           7.000000          7.00000   \n",
       "max      8698.000000   2.419806e+07        1798.000000       1499.00000   \n",
       "\n",
       "       Interest_Rate    Num_of_Loan  Delay_from_due_date  \\\n",
       "count  100000.000000  100000.000000        100000.000000   \n",
       "mean       72.466040       3.009960            21.068780   \n",
       "std       466.422621      62.647879            14.860104   \n",
       "min         1.000000    -100.000000            -5.000000   \n",
       "25%         8.000000       1.000000            10.000000   \n",
       "50%        13.000000       3.000000            18.000000   \n",
       "75%        20.000000       5.000000            28.000000   \n",
       "max      5797.000000    1496.000000            67.000000   \n",
       "\n",
       "       Changed_Credit_Limit  Num_Credit_Inquiries  Outstanding_Debt  \\\n",
       "count         100000.000000          98035.000000     100000.000000   \n",
       "mean              10.171791             27.754251       1426.220376   \n",
       "std                6.880628            193.177339       1155.129026   \n",
       "min               -6.490000              0.000000          0.230000   \n",
       "25%                4.970000              3.000000        566.072500   \n",
       "50%                9.250000              6.000000       1166.155000   \n",
       "75%               14.660000              9.000000       1945.962500   \n",
       "max               36.970000           2597.000000       4998.070000   \n",
       "\n",
       "       Credit_Utilization_Ratio  Total_EMI_per_month  Amount_invested_monthly  \\\n",
       "count             100000.000000        100000.000000             95521.000000   \n",
       "mean                  32.285173          1403.118217               637.412998   \n",
       "std                    5.116875          8306.041270              2043.319327   \n",
       "min                   20.000000             0.000000                 0.000000   \n",
       "25%                   28.052567            30.306660                74.534002   \n",
       "50%                   32.305784            69.249473               135.925682   \n",
       "75%                   36.496663           161.224249               265.731733   \n",
       "max                   50.000000         82331.000000             10000.000000   \n",
       "\n",
       "       Monthly_Balance  \n",
       "count     9.713200e+04  \n",
       "mean      3.088580e+12  \n",
       "std       3.208492e+14  \n",
       "min       7.759665e-03  \n",
       "25%       2.700037e+02  \n",
       "50%       3.364770e+02  \n",
       "75%       4.696852e+02  \n",
       "max       3.333333e+16  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SE VERIFICA:\n",
    "df_temp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SE CREA LISTADO (CLASIFICACION DE VARIABLES)\n",
    "\n",
    "catGen=[col for col in df_temp.columns if (df_temp[col].dtypes=='object')]\n",
    "numGen=[col for col in df_temp.columns if ((df_temp[col].dtypes!='object'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82482, 23)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BALANCEO DE VARIABLE CATEGORICA\n",
    "\n",
    "df_standard = df_temp[df_temp['Credit_Score'] == 'Standard']\n",
    "df_poor = df_temp[df_temp['Credit_Score'] == 'Poor']\n",
    "df_good = df_temp[df_temp['Credit_Score'] == 'Good']\n",
    "cantidadstandard = 2*df_good.shape[0]\n",
    "df_standard = df_standard.sample(n=cantidadstandard, random_state=2023)\n",
    "df_temp = pd.concat([df_standard, df_poor, df_good])\n",
    "df_temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPUTACION VARIABLE CATEGORICA\n",
    "\n",
    "# Se elimina faltantes de comportamiento de pago debido a que son particulares a cada cliente. CCA\n",
    "df_temp = df_temp[df_temp['Payment_Behaviour'].str.contains('!@9#%8') == False]\n",
    "# Se desconoce Ocupacion de persona asi que se coloca como otra\n",
    "df_temp['Occupation'] = df_temp['Occupation'].str.replace('_______', 'Other')\n",
    "# Se coloca desconocido al mix de credito pues es un comportamiento muy particular y puede tratarse de personas recien ingresadas\n",
    "df_temp['Credit_Mix'] = df_temp['Credit_Mix'].str.replace('_', 'Unknown')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPUTACION VARIABLE NUMERICA\n",
    "\n",
    "# Imputacion con la media\n",
    "df_temp['Num_Credit_Inquiries']=np.round(df_temp['Num_Credit_Inquiries'].fillna(df_temp['Num_Credit_Inquiries'].mean()))\n",
    "df_temp['Monthly_Balance']=np.round(df_temp['Monthly_Balance'].fillna(df_temp['Monthly_Balance'].mean()))\n",
    "\n",
    "# Imputacion con la mediana\n",
    "df_temp['Amount_invested_monthly']=np.round(df_temp['Amount_invested_monthly'].fillna(df_temp['Amount_invested_monthly'].median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRATAMIENTO DE OUTLIERS\n",
    "\n",
    "def detectOutliersLimits (dataset,col):\n",
    "# Descripcion: calcula limites superiores e inferiores para identificar outliers\n",
    "# input: dataset->dataframe pandas\n",
    "# output: tupla de floats con los limites\n",
    "    IQR=dataset[col].quantile(0.75)-dataset[col].quantile(0.25)\n",
    "    LI=dataset[col].quantile(0.25)-(IQR*1.75)\n",
    "    LS=dataset[col].quantile(0.75)+(IQR*1.75)\n",
    "\n",
    "    return LI,LS\n",
    "\n",
    "\n",
    "def Capping(data,colist):\n",
    "# Descripcion: convierte outliers en limites superiores e inferiores\n",
    "# input: data->dataframe pandas, colist-> arreglo con el nombre de las columnas\n",
    "# output: transforma el dataframe ingresado en las columnas especificadas\n",
    "    for c in colist:\n",
    "        LI,LS=detectOutliersLimits(data,c)\n",
    "        if '_code' in c:\n",
    "            data[c]=data[c]\n",
    "        else:\n",
    "            data[c]=np.where(data[c]>LS,LS,\n",
    "                                    np.where(data[c]<LI,LI,data[c]))\n",
    "\n",
    "continuas=['Annual_Income', 'Interest_Rate','Delay_from_due_date','Changed_Credit_Limit','Outstanding_Debt','Credit_Utilization_Ratio',\n",
    "            'Total_EMI_per_month','Amount_invested_monthly','Monthly_Balance','Num_Bank_Accounts','Num_Credit_Card','Num_Credit_Inquiries']\n",
    "\n",
    "Capping(df_temp,continuas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminando valores menores a 0 para transformacion de variables continuas\n",
    "\n",
    "for col in continuas:\n",
    "    minimo=df_temp[col].min()\n",
    "    if minimo<=0:\n",
    "        df_temp[col]=df_temp[col]+abs(minimo)+1\n",
    "    else:\n",
    "        df_temp[col]=df_temp[col]\n",
    "\n",
    "# Aplicando transformacion yeon\n",
    "\n",
    "for c in df_temp[continuas].columns: \n",
    "    df_temp[c],_=stats.yeojohnson(df_temp[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Standard    32991\n",
       "Poor        26773\n",
       "Good        16445\n",
       "Name: Credit_Score, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp['Credit_Score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificacion variables categoricas\n",
    "\n",
    "CATEGORICAL_VARS = ['SSN','Occupation','Payment_of_Min_Amount','Payment_Behaviour','Month','Credit_Mix','Credit_Score']\n",
    "\n",
    "for c in df_temp[CATEGORICAL_VARS].columns:\n",
    "    Variable_freq_mapper=(df_temp[c].value_counts().sort_values(ascending=False)).to_dict()\n",
    "    df_temp[c]=df_temp[c].map(Variable_freq_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionando final\n",
    "\n",
    "df_final=df_temp.copy()[[ \n",
    "'Annual_Income',\n",
    "'Interest_Rate',\n",
    "'Outstanding_Debt',\n",
    "'Num_Bank_Accounts',\n",
    "'Num_Credit_Card',\n",
    "'Num_Credit_Inquiries',\n",
    "'Delay_from_due_date',\n",
    "'Monthly_Balance',\n",
    "'Month',\n",
    "'SSN',\n",
    "'Occupation',\n",
    "'Credit_Mix',\n",
    "'Payment_of_Min_Amount',\n",
    "'Payment_Behaviour',\n",
    " 'Credit_Score']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 76209 entries, 79102 to 99983\n",
      "Data columns (total 15 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Annual_Income          76209 non-null  float64\n",
      " 1   Interest_Rate          76209 non-null  float64\n",
      " 2   Outstanding_Debt       76209 non-null  float64\n",
      " 3   Num_Bank_Accounts      76209 non-null  float64\n",
      " 4   Num_Credit_Card        76209 non-null  float64\n",
      " 5   Num_Credit_Inquiries   76209 non-null  float64\n",
      " 6   Delay_from_due_date    76209 non-null  float64\n",
      " 7   Monthly_Balance        76209 non-null  float64\n",
      " 8   Month                  76209 non-null  int64  \n",
      " 9   SSN                    76209 non-null  int64  \n",
      " 10  Occupation             76209 non-null  int64  \n",
      " 11  Credit_Mix             76209 non-null  int64  \n",
      " 12  Payment_of_Min_Amount  76209 non-null  int64  \n",
      " 13  Payment_Behaviour      76209 non-null  int64  \n",
      " 14  Credit_Score           76209 non-null  int64  \n",
      "dtypes: float64(8), int64(7)\n",
      "memory usage: 9.3 MB\n"
     ]
    }
   ],
   "source": [
    "df_final.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construccion de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Annual_Income</th>\n",
       "      <th>Interest_Rate</th>\n",
       "      <th>Outstanding_Debt</th>\n",
       "      <th>Num_Bank_Accounts</th>\n",
       "      <th>Num_Credit_Card</th>\n",
       "      <th>Num_Credit_Inquiries</th>\n",
       "      <th>Delay_from_due_date</th>\n",
       "      <th>Monthly_Balance</th>\n",
       "      <th>Month</th>\n",
       "      <th>SSN</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Credit_Mix</th>\n",
       "      <th>Payment_of_Min_Amount</th>\n",
       "      <th>Payment_Behaviour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79102</th>\n",
       "      <td>13.879781</td>\n",
       "      <td>7.184026</td>\n",
       "      <td>58.541470</td>\n",
       "      <td>5.256536</td>\n",
       "      <td>3.375337</td>\n",
       "      <td>3.523152</td>\n",
       "      <td>5.054458</td>\n",
       "      <td>17.927258</td>\n",
       "      <td>9616</td>\n",
       "      <td>2</td>\n",
       "      <td>4829</td>\n",
       "      <td>15216</td>\n",
       "      <td>39229</td>\n",
       "      <td>14362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52133</th>\n",
       "      <td>11.377149</td>\n",
       "      <td>3.399717</td>\n",
       "      <td>37.041828</td>\n",
       "      <td>5.256536</td>\n",
       "      <td>3.055745</td>\n",
       "      <td>2.073700</td>\n",
       "      <td>4.197932</td>\n",
       "      <td>15.795480</td>\n",
       "      <td>9663</td>\n",
       "      <td>5</td>\n",
       "      <td>4829</td>\n",
       "      <td>25603</td>\n",
       "      <td>39229</td>\n",
       "      <td>21209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76068</th>\n",
       "      <td>13.132980</td>\n",
       "      <td>5.505791</td>\n",
       "      <td>47.697123</td>\n",
       "      <td>5.256536</td>\n",
       "      <td>3.375337</td>\n",
       "      <td>4.040135</td>\n",
       "      <td>4.326818</td>\n",
       "      <td>16.881846</td>\n",
       "      <td>9581</td>\n",
       "      <td>8</td>\n",
       "      <td>4829</td>\n",
       "      <td>15216</td>\n",
       "      <td>39229</td>\n",
       "      <td>14362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99657</th>\n",
       "      <td>14.527234</td>\n",
       "      <td>2.856283</td>\n",
       "      <td>24.264774</td>\n",
       "      <td>5.256536</td>\n",
       "      <td>3.673012</td>\n",
       "      <td>2.378805</td>\n",
       "      <td>4.616967</td>\n",
       "      <td>24.298353</td>\n",
       "      <td>9478</td>\n",
       "      <td>8</td>\n",
       "      <td>5430</td>\n",
       "      <td>25603</td>\n",
       "      <td>39229</td>\n",
       "      <td>11537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37405</th>\n",
       "      <td>12.455433</td>\n",
       "      <td>4.674039</td>\n",
       "      <td>27.604758</td>\n",
       "      <td>3.355321</td>\n",
       "      <td>2.709090</td>\n",
       "      <td>3.329015</td>\n",
       "      <td>3.911687</td>\n",
       "      <td>16.802644</td>\n",
       "      <td>9663</td>\n",
       "      <td>6</td>\n",
       "      <td>4764</td>\n",
       "      <td>25603</td>\n",
       "      <td>39229</td>\n",
       "      <td>9337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Annual_Income  Interest_Rate  Outstanding_Debt  Num_Bank_Accounts  \\\n",
       "79102      13.879781       7.184026         58.541470           5.256536   \n",
       "52133      11.377149       3.399717         37.041828           5.256536   \n",
       "76068      13.132980       5.505791         47.697123           5.256536   \n",
       "99657      14.527234       2.856283         24.264774           5.256536   \n",
       "37405      12.455433       4.674039         27.604758           3.355321   \n",
       "\n",
       "       Num_Credit_Card  Num_Credit_Inquiries  Delay_from_due_date  \\\n",
       "79102         3.375337              3.523152             5.054458   \n",
       "52133         3.055745              2.073700             4.197932   \n",
       "76068         3.375337              4.040135             4.326818   \n",
       "99657         3.673012              2.378805             4.616967   \n",
       "37405         2.709090              3.329015             3.911687   \n",
       "\n",
       "       Monthly_Balance  Month  SSN  Occupation  Credit_Mix  \\\n",
       "79102        17.927258   9616    2        4829       15216   \n",
       "52133        15.795480   9663    5        4829       25603   \n",
       "76068        16.881846   9581    8        4829       15216   \n",
       "99657        24.298353   9478    8        5430       25603   \n",
       "37405        16.802644   9663    6        4764       25603   \n",
       "\n",
       "       Payment_of_Min_Amount  Payment_Behaviour  \n",
       "79102                  39229              14362  \n",
       "52133                  39229              21209  \n",
       "76068                  39229              14362  \n",
       "99657                  39229              11537  \n",
       "37405                  39229               9337  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_final.drop(['Credit_Score'], axis=1)\n",
    "y = df_final['Credit_Score']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_std = scaler.transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN modelo de clasificacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\50259\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.73791849435759"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "knn.fit(X_train_std , y_train)\n",
    "knn_score_train=knn.score(X_train_std , y_train)\n",
    "knn_score_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\50259\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>32991</th>\n",
       "      <th>16445</th>\n",
       "      <th>26773</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32991</th>\n",
       "      <td>3380</td>\n",
       "      <td>353</td>\n",
       "      <td>1219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16445</th>\n",
       "      <td>758</td>\n",
       "      <td>5752</td>\n",
       "      <td>1475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26773</th>\n",
       "      <td>1620</td>\n",
       "      <td>2235</td>\n",
       "      <td>6071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       32991  16445  26773\n",
       "32991   3380    353   1219\n",
       "16445    758   5752   1475\n",
       "26773   1620   2235   6071"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "knn_preds = knn.predict(X_test_std)\n",
    "\n",
    "cm = confusion_matrix(y_test, knn_preds)\n",
    "cm_df = pd.DataFrame(cm, index = [32991,16445,26773], columns = [32991,16445,26773])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       16445       0.59      0.68      0.63      4952\n",
      "       26773       0.69      0.72      0.70      7985\n",
      "       32991       0.69      0.61      0.65      9926\n",
      "\n",
      "    accuracy                           0.66     22863\n",
      "   macro avg       0.66      0.67      0.66     22863\n",
      "weighted avg       0.67      0.66      0.66     22863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, knn_preds))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb_preds = gnb.fit(X_train_std, y_train).predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       16445       0.53      0.74      0.62      4952\n",
      "       26773       0.70      0.71      0.71      7985\n",
      "       32991       0.71      0.56      0.63      9926\n",
      "\n",
      "    accuracy                           0.65     22863\n",
      "   macro avg       0.65      0.67      0.65     22863\n",
      "weighted avg       0.67      0.65      0.65     22863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, gnb_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 100 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'var_smoothing': 0.0006579332246575676}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "params_NB = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "gs_NB = GridSearchCV(estimator=gnb, \n",
    "                 param_grid=params_NB, \n",
    "                 cv=KFold(n_splits=20, shuffle=True, random_state=2023),   \n",
    "                 verbose=1, \n",
    "                 scoring='accuracy') \n",
    "gs_NB.fit(X_train_std, y_train)\n",
    "\n",
    "gs_NB.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       16445       0.53      0.74      0.62      4952\n",
      "       26773       0.70      0.71      0.71      7985\n",
      "       32991       0.71      0.56      0.63      9926\n",
      "\n",
      "    accuracy                           0.65     22863\n",
      "   macro avg       0.65      0.67      0.65     22863\n",
      "weighted avg       0.67      0.65      0.65     22863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB(var_smoothing= 0.0006579332246575676)\n",
    "gnb_preds = gnb.fit(X_train_std, y_train).predict(X_test_std)\n",
    "print(classification_report(y_test, gnb_preds))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Regresion Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\50259\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "120 fits failed out of a total of 240.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\50259\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\50259\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\50259\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\50259\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\50259\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 441, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\50259\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores HyperParámetros: {'C': 0.01, 'penalty': 'l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\50259\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\50259\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logit = LogisticRegression(solver='saga')\n",
    " \n",
    "hyperparams_grid = {'penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "                                     'C': [0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=logit, param_grid=hyperparams_grid, scoring=['roc_auc', 'accuracy'], refit='roc_auc', n_jobs =-1, \n",
    "                                                                                     cv=KFold(n_splits=20, shuffle=True, random_state=2023))\n",
    "grid_search.fit(X_train_std, y_train)\n",
    "\n",
    "accuracies = grid_search.cv_results_['mean_test_accuracy']\n",
    "roc_aucs = grid_search.cv_results_['mean_test_roc_auc']\n",
    "\n",
    "mean_acc =  np.mean([x for x in accuracies if not np.isnan(x)])\n",
    "mean_roc_aucs = np.mean([x for x in roc_aucs if not np.isnan(x)])\n",
    "\n",
    "print(f'Mejores HyperParámetros: {grid_search.best_params_}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([26773, 32991, 32991, ..., 32991, 32991, 26773], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = LogisticRegression(solver='saga',C= 0.01, penalty= 'l1')\n",
    "logit.fit(X_train_std, y_train)\n",
    "\n",
    "logit_preds = logit.predict(X_test_std)\n",
    "logit_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       16445       0.59      0.55      0.57      4952\n",
      "       26773       0.70      0.65      0.67      7985\n",
      "       32991       0.60      0.66      0.63      9926\n",
      "\n",
      "    accuracy                           0.63     22863\n",
      "   macro avg       0.63      0.62      0.62     22863\n",
      "weighted avg       0.63      0.63      0.63     22863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, logit_preds))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores HyperParámetros: {'shrinkage': 1} acc: 0.6310317680492337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\50259\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\50259\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(solver='lsqr')\n",
    " \n",
    "hyperparams_grid = {'shrinkage': [0.01,0.1,1]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=lda, param_grid=hyperparams_grid, scoring=['accuracy'], refit='accuracy', n_jobs =-1, \n",
    "                                                                                     cv=KFold(n_splits=20, shuffle=True, random_state=2023))\n",
    "grid_search.fit(X_train_std, y_train)\n",
    "\n",
    "accuracies = grid_search.cv_results_['mean_test_accuracy']\n",
    "\n",
    "\n",
    "\n",
    "mean_roc_aucs = np.mean([x for x in roc_aucs if not np.isnan(x)])\n",
    "\n",
    "print(f'Mejores HyperParámetros: {grid_search.best_params_} acc: {np.mean([x for x in accuracies if not np.isnan(x)])}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       16445       0.52      0.70      0.59      4952\n",
      "       26773       0.70      0.70      0.70      7985\n",
      "       32991       0.67      0.56      0.61      9926\n",
      "\n",
      "    accuracy                           0.64     22863\n",
      "   macro avg       0.63      0.65      0.63     22863\n",
      "weighted avg       0.65      0.64      0.64     22863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis(solver='lsqr',shrinkage=1)\n",
    "lda.fit(X_train_std, y_train)\n",
    "lda_preds = lda.predict(X_test_std)\n",
    "print(classification_report(y_test, lda_preds))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hecho en 23.168s\n",
      "Mejores HyperParámetros: {'max_depth': 10, 'max_features': 14} acc: 0.7194962733762478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\50259\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\50259\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree  import DecisionTreeClassifier\n",
    "\n",
    "t0 = time()\n",
    "tree= DecisionTreeClassifier()\n",
    " \n",
    "hyperparams_grid = {   \"max_depth\": [8,10,12,15],\n",
    "                        \"max_features\":[14,10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=tree, param_grid=hyperparams_grid, scoring=['accuracy'], refit='accuracy', n_jobs =-1, \n",
    "                                                                                     cv=KFold(n_splits=20, shuffle=True, random_state=2023))\n",
    "grid_search.fit(X_train_std, y_train)\n",
    "\n",
    "accuracies = grid_search.cv_results_['mean_test_accuracy']\n",
    "\n",
    "mean_roc_aucs = np.mean([x for x in roc_aucs if not np.isnan(x)])\n",
    "\n",
    "print(\"Hecho en %0.3fs\" % (time() - t0))\n",
    "print(f'Mejores HyperParámetros: {grid_search.best_params_} acc: {np.mean([x for x in accuracies if not np.isnan(x)])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       16445       0.63      0.71      0.67      4952\n",
      "       26773       0.77      0.75      0.76      7985\n",
      "       32991       0.74      0.71      0.72      9926\n",
      "\n",
      "    accuracy                           0.72     22863\n",
      "   macro avg       0.71      0.72      0.72     22863\n",
      "weighted avg       0.73      0.72      0.72     22863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(max_depth= 10, max_features=14)\n",
    "tree.fit(X_train_std, y_train)\n",
    "tree_preds = tree.predict(X_test_std)\n",
    "print(classification_report(y_test, tree_preds))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hecho en 66.172s\n",
      "Mejores HyperParámetros: {'learning_rate': 0.8, 'n_estimators': 12} acc: 0.6642986120831598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\50259\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\50259\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada = AdaBoostClassifier() \n",
    "\n",
    "hyperparams_grid = {   \"n_estimators\": [8,10,12],\n",
    "                        \"learning_rate\":[0.5,0.8]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=ada, param_grid=hyperparams_grid, scoring=['accuracy'], refit='accuracy', n_jobs =-1, \n",
    "                                                                                     cv=KFold(n_splits=20, shuffle=True, random_state=2023))\n",
    "grid_search.fit(X_train_std, y_train)\n",
    "\n",
    "accuracies = grid_search.cv_results_['mean_test_accuracy']\n",
    "\n",
    "mean_roc_aucs = np.mean([x for x in roc_aucs if not np.isnan(x)])\n",
    "\n",
    "print(\"Hecho en %0.3fs\" % (time() - t0))\n",
    "print(f'Mejores HyperParámetros: {grid_search.best_params_} acc: {np.mean([x for x in accuracies if not np.isnan(x)])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       16445       0.58      0.68      0.63      4952\n",
      "       26773       0.75      0.67      0.71      7985\n",
      "       32991       0.68      0.68      0.68      9926\n",
      "\n",
      "    accuracy                           0.68     22863\n",
      "   macro avg       0.67      0.68      0.67     22863\n",
      "weighted avg       0.68      0.68      0.68     22863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ada = AdaBoostClassifier(learning_rate= 0.8, n_estimators= 12) \n",
    "ada.fit(X_train_std, y_train)\n",
    "ada_preds = ada.predict(X_test_std)\n",
    "print(classification_report(y_test, ada_preds))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hecho en 175.415s\n",
      "Mejores HyperParámetros: {'learning_rate': 0.5, 'max_depth': 5, 'n_estimators': 5, 'random_state': 10} acc: 0.711349020020361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\50259\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\50259\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#este modelo necesita que la codificacion empiece en cero por lo que se realiza la transformacion:\n",
    "le = LabelEncoder()\n",
    "y_train2 = le.fit_transform(y_train)\n",
    "\n",
    "xgb = XGBClassifier(objective = 'binary:logistic')\n",
    "\n",
    "hyperparams_grid = {   \"max_depth\": [3,5],\n",
    "                        \"learning_rate\":[0.5,0.3],\n",
    "                        \"n_estimators\":[3,5],\n",
    "                        \"random_state\":[10,42]\n",
    "\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb, param_grid=hyperparams_grid, scoring=['accuracy'], refit='accuracy', n_jobs =-1, \n",
    "                                                                                     cv=KFold(n_splits=20, shuffle=True, random_state=2023))\n",
    "grid_search.fit(X_train_std, y_train2)\n",
    "\n",
    "accuracies = grid_search.cv_results_['mean_test_accuracy']\n",
    "\n",
    "mean_roc_aucs = np.mean([x for x in roc_aucs if not np.isnan(x)])\n",
    "\n",
    "print(\"Hecho en %0.3fs\" % (time() - t0))\n",
    "print(f'Mejores HyperParámetros: {grid_search.best_params_} acc: {np.mean([x for x in accuracies if not np.isnan(x)])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.73      0.67      4952\n",
      "           1       0.76      0.77      0.76      7985\n",
      "           2       0.75      0.68      0.72      9926\n",
      "\n",
      "    accuracy                           0.72     22863\n",
      "   macro avg       0.71      0.73      0.72     22863\n",
      "weighted avg       0.73      0.72      0.72     22863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(objective = 'binary:logistic',learning_rate= 0.5, max_depth=5, n_estimators=5, random_state= 10)\n",
    "xgb.fit(X_train_std, y_train2)\n",
    "xgb_preds = xgb.predict(X_test_std)\n",
    "y_test2 = le.fit_transform(y_test)\n",
    "print(classification_report(y_test2, xgb_preds))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hecho en 248.771s\n",
      "Mejores HyperParámetros: {'learning_rate': 0.5, 'max_depth': 8, 'n_estimators': 6, 'random_state': 12} acc: 0.7250845541796032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\50259\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\50259\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "lg=lgb.LGBMClassifier()\n",
    "\n",
    "hyperparams_grid = {   \"max_depth\": [8,12],\n",
    "                        \"learning_rate\":[0.5,0.8],\n",
    "                        \"n_estimators\":[4,6],\n",
    "                        \"random_state\":[12,42]\n",
    "\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=lg, param_grid=hyperparams_grid, scoring=['accuracy'], refit='accuracy', n_jobs =-1, \n",
    "                                                                                     cv=KFold(n_splits=20, shuffle=True, random_state=2023))\n",
    "grid_search.fit(X_train_std, y_train)\n",
    "\n",
    "accuracies = grid_search.cv_results_['mean_test_accuracy']\n",
    "\n",
    "mean_roc_aucs = np.mean([x for x in roc_aucs if not np.isnan(x)])\n",
    "\n",
    "print(\"Hecho en %0.3fs\" % (time() - t0))\n",
    "print(f'Mejores HyperParámetros: {grid_search.best_params_} acc: {np.mean([x for x in accuracies if not np.isnan(x)])}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       16445       0.64      0.73      0.68      4952\n",
      "       26773       0.76      0.77      0.77      7985\n",
      "       32991       0.76      0.69      0.72      9926\n",
      "\n",
      "    accuracy                           0.73     22863\n",
      "   macro avg       0.72      0.73      0.72     22863\n",
      "weighted avg       0.73      0.73      0.73     22863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lg=lgb.LGBMClassifier(learning_rate= 0.5, max_depth= 12, n_estimators=6, random_state=12)\n",
    "lg.fit(X_train_std, y_train)\n",
    "lg_preds = lg.predict(X_test_std)\n",
    "print(classification_report(y_test, lg_preds))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LQDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hecho en 256.624s\n",
      "Mejores HyperParámetros: {'reg_param': 0.2, 'store_covariance': True} acc: 0.653901280986803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\50259\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\50259\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "lq=QuadraticDiscriminantAnalysis()\n",
    "\n",
    "hyperparams_grid = {   \"reg_param\": [0.15,0.2,0.5],\n",
    "                        \"store_covariance\":[True,False]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=lq, param_grid=hyperparams_grid, scoring=['accuracy'], refit='accuracy', n_jobs =-1, \n",
    "                                                                                     cv=KFold(n_splits=20, shuffle=True, random_state=2023))\n",
    "grid_search.fit(X_train_std, y_train)\n",
    "\n",
    "accuracies = grid_search.cv_results_['mean_test_accuracy']\n",
    "\n",
    "mean_roc_aucs = np.mean([x for x in roc_aucs if not np.isnan(x)])\n",
    "\n",
    "print(\"Hecho en %0.3fs\" % (time() - t0))\n",
    "print(f'Mejores HyperParámetros: {grid_search.best_params_} acc: {np.mean([x for x in accuracies if not np.isnan(x)])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       16445       0.64      0.73      0.68      4952\n",
      "       26773       0.76      0.77      0.77      7985\n",
      "       32991       0.76      0.69      0.72      9926\n",
      "\n",
      "    accuracy                           0.73     22863\n",
      "   macro avg       0.72      0.73      0.72     22863\n",
      "weighted avg       0.73      0.73      0.73     22863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lq=QuadraticDiscriminantAnalysis(reg_param= 0.2, store_covariance=True)\n",
    "lq.fit(X_train_std, y_train)\n",
    "lq_preds = lg.predict(X_test_std)\n",
    "print(classification_report(y_test, lq_preds))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hecho en 914.449s\n",
      "Mejores HyperParámetros: {'max_depth': 12, 'max_features': 10} acc: 0.736816910372148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\50259\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\50259\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble  import RandomForestClassifier\n",
    "\n",
    "rf= RandomForestClassifier()\n",
    " \n",
    "hyperparams_grid = {   \"max_depth\": [8,12],\n",
    "                        \"max_features\":[6,10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=hyperparams_grid, scoring=['accuracy'], refit='accuracy', n_jobs =-1, \n",
    "                                                                                     cv=KFold(n_splits=20, shuffle=True, random_state=2023))\n",
    "grid_search.fit(X_train_std, y_train)\n",
    "\n",
    "accuracies = grid_search.cv_results_['mean_test_accuracy']\n",
    "\n",
    "mean_roc_aucs = np.mean([x for x in roc_aucs if not np.isnan(x)])\n",
    "\n",
    "print(\"Hecho en %0.3fs\" % (time() - t0))\n",
    "print(f'Mejores HyperParámetros: {grid_search.best_params_} acc: {np.mean([x for x in accuracies if not np.isnan(x)])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       16445       0.65      0.75      0.70      4952\n",
      "       26773       0.79      0.79      0.79      7985\n",
      "       32991       0.77      0.72      0.75      9926\n",
      "\n",
      "    accuracy                           0.75     22863\n",
      "   macro avg       0.74      0.75      0.75     22863\n",
      "weighted avg       0.75      0.75      0.75     22863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf= RandomForestClassifier(max_depth=12, max_features=10)\n",
    "rf.fit(X_train_std, y_train)\n",
    "rf_preds = rf.predict(X_test_std)\n",
    "print(classification_report(y_test, rf_preds))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm  import SVC\n",
    "\n",
    "svm= SVC()\n",
    " \n",
    "hyperparams_grid = {   \"shrinking\": [True,False]                        \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=svm, param_grid=hyperparams_grid, scoring=['accuracy'], refit='accuracy', n_jobs =-1, \n",
    "                                                                                     cv=KFold(n_splits=20, shuffle=True, random_state=2023))\n",
    "grid_search.fit(X_train_std, y_train)\n",
    "\n",
    "accuracies = grid_search.cv_results_['mean_test_accuracy']\n",
    "\n",
    "mean_roc_aucs = np.mean([x for x in roc_aucs if not np.isnan(x)])\n",
    "\n",
    "print(\"Hecho en %0.3fs\" % (time() - t0))\n",
    "print(f'Mejores HyperParámetros: {grid_search.best_params_} acc: {np.mean([x for x in accuracies if not np.isnan(x)])}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones\n",
    "\n",
    "Por las metricas obtenidas el listado de modelos de mejor a peor se encuentra ordenado como:\n",
    "\n",
    "1. Random Forrest \n",
    "2. LQDA\n",
    "3. LGBM\n",
    "4. Decision Tree\n",
    "5. XGBoost\n",
    "6. KNN\n",
    "7. AdaBoost\n",
    "8. Naive Bayes\n",
    "9. LDA\n",
    "10. Logistic Regression\n",
    "\n",
    "No obstante, al momento de comparar el tiempo de entrenamiento necesario para cada modelo se opto por utilizar Decision Tree\n",
    "debido a que no consume tanto tiempo ni recurso de procesamiento de la computadora en comparacion al resto de modelos y se tienen \n",
    "resultados efectivos\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
